{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9bf86-7131-45c6-a3fb-5cc7a6fdb072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample from a trained model\n",
    "\"\"\"\n",
    "import re, sys\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "#from contextlib import nullcontext\n",
    "import torch\n",
    "#import tiktoken\n",
    "from model_ukb import GPTConfig, GPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.infer import Predictive\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "import probcox as pcox\n",
    "\n",
    "def predictor(data):\n",
    "    theta =  pyro.sample(\"theta\", dist.StudentT(1, loc=0, scale=0.001).expand([data[1].shape[1], 1])).type(torch.float32)\n",
    "    pred = torch.mm(data[1], theta)\n",
    "    return(pred)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = 'out-ukb' # ignored if init_from is not 'resume'\n",
    "start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 10 # number of samples to draw\n",
    "max_new_tokens = 10 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'cpu' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype ='float64'#'bfloat16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "t_min = 100.0\n",
    "#exec(open('configurator.py').read()) # overrides from command line or config file\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'float64': torch.float64, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "#ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "load_meta=True\n",
    "meta_path='data/ukb/meta.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea6ae1-4fdc-4a5f-850a-db80c231a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subsample = 1024\n",
    "target = 'E11'\n",
    "iter_ = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "276d091e-84e5-4d2d-9a25-ce48bec57655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E11'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_short[215][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03826043-1d44-4180-8039-a981994a983a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(labels_short=='M10')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06623279-0431-4568-8aea-cc6a866a512a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7068e2-fc45-4065-8ffa-08cd329e9dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a678a-5666-440c-b00f-9f8b15dc6acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b429fb-505d-47b3-8b56-4a2ba6fe7d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Padding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMI_low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>D46 Myelodysplastic syndromes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>D47 Other neoplasms of uncertain or unknown be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>D48 Neoplasm of uncertain or unknown behaviour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>O01 Hydatidiform mole38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>Death</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1270 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0                                               Padding\n",
       "1                                               Healthy\n",
       "2                                                Female\n",
       "3                                                  Male\n",
       "4                                               BMI_low\n",
       "...                                                 ...\n",
       "1265                      D46 Myelodysplastic syndromes\n",
       "1266  D47 Other neoplasms of uncertain or unknown be...\n",
       "1267  D48 Neoplasm of uncertain or unknown behaviour...\n",
       "1268                            O01 Hydatidiform mole38\n",
       "1269                                              Death\n",
       "\n",
       "[1270 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"data/ukb/labels.csv\", header=None, sep=\"\\t\")\n",
    "labels_long = np.asarray(labels)\n",
    "labels_short = np.asarray(labels).astype('S3').astype(str)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c63849-e4d7-4388-92b5-64a6047f634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = np.fromfile('/nfs/research/sds/sds-ukb-cancer/projects/gpt/data/pre.bin', dtype=np.uint32).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59140ea1-1c60-4e26-85ad-687120d5bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p2i(data):\n",
    "    px = data[:,0].astype('int')\n",
    "    pix = sorted(list(set(px)))\n",
    "    #p2i = np.array([(p, (px==p).argmax(), (px==p).sum()) for i,p in enumerate(pix)])\n",
    "    p2i = []\n",
    "    j = 0\n",
    "    q = px[0]\n",
    "    for i,p in enumerate(px):\n",
    "        if p != q:\n",
    "            p2i.append([j,i-j])\n",
    "            q = p\n",
    "            j = i\n",
    "    return np.array(p2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a099c88-02d0-4912-9a8c-009e269661c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_p2i = get_p2i(pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a2fc86-9bd7-4eb7-8941-0e487fb1d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre[:, -1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cce64a-7b70-4805-9d34-d645e8c5defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longformat(pre, pre_p2i, sindx, labels, target):\n",
    "    \n",
    "    time = []\n",
    "    rindx = []\n",
    "    cindx = []\n",
    "    values = []\n",
    "    rmax = 0\n",
    "    for ii in sindx:\n",
    "        x = pre[pre_p2i[ii, 0]:pre_p2i[ii, 0]+pre_p2i[ii, 1], 2].astype(int)\n",
    "        a = pre[pre_p2i[ii, 0]:pre_p2i[ii, 0]+pre_p2i[ii, 1], 1].astype(np.float32)\n",
    "        a[-1] = a[-1] + 1\n",
    "        \n",
    "        eindx = np.where(target == labels)[0]\n",
    "        event = np.any(x == eindx)\n",
    "        \n",
    "        if event: \n",
    "            event_age = a[np.where(x == eindx)[0][0]]\n",
    "            indx = a < event_age\n",
    "            x = x[indx]\n",
    "            a = a[indx]\n",
    "            a = np.concatenate((a, np.asarray([event_age])))\n",
    "\n",
    "        au = np.unique(a)\n",
    "        time_ = np.concatenate((au[:-1, None], au[1:, None], np.zeros((au.shape[0]-1, 1))), axis=1)\n",
    "        \n",
    "        if event: \n",
    "            cindx_ = x.tolist()\n",
    "            time_[-1, -1] = 1\n",
    "        else:\n",
    "            cindx_ = (x[:-1]).tolist()\n",
    "            \n",
    "        time_ = time_.tolist()\n",
    "        rindx_ = np.asarray([np.where(aa==au)[0][0] for aa in a[:-1]])\n",
    "        rindx_max = np.max(rindx_)\n",
    "        \n",
    "        # expand cumulative \n",
    "        cindx_cum = []\n",
    "        rindx_cum = []\n",
    "        for kk in range(len(rindx_)):\n",
    "            rrep = np.arange(rindx_[kk], rindx_max+1)\n",
    "            rindx_cum.extend(rrep.tolist())\n",
    "            cindx_cum.extend(np.repeat(cindx_[kk], rrep.shape[0]).tolist())\n",
    "        rindx_cum = np.asarray(rindx_cum)\n",
    "\n",
    "        rindx_cum = rindx_cum + rmax\n",
    "        rmax = np.max(rindx_cum)+1\n",
    "        rindx_cum = rindx_cum.tolist()\n",
    "        values_ = np.ones((len(rindx_cum), )).tolist()\n",
    "        time.extend(time_)\n",
    "        rindx.extend(rindx_cum)\n",
    "        cindx.extend(cindx_cum)\n",
    "        values.extend(values_)\n",
    "\n",
    "    time = torch.tensor(time).type(torch.float32)\n",
    "    Xs = torch.sparse_coo_tensor(torch.cat((torch.tensor(rindx)[None, :], torch.tensor(cindx)[None, :])), torch.tensor(values), (rmax, labels.shape[0]))\n",
    "\n",
    "    return(time, Xs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59484a-fbda-45a7-ab0a-3bb66c20287d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/torch/distributions/distribution.py:46: UserWarning: <class 'probcox.probcox.CoxPartialLikelihood'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
      "  'with `validate_args=False` to turn off validation.')\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:71: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.sampling_proportion[0] = torch.tensor([self.sampling_proportion[0]])\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:71: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  self.sampling_proportion[0] = torch.tensor([self.sampling_proportion[0]])\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:72: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.sampling_proportion[1] = torch.tensor([self.sampling_proportion[1]])\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:72: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  self.sampling_proportion[1] = torch.tensor([self.sampling_proportion[1]])\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:73: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.sampling_proportion[2] = torch.tensor([self.sampling_proportion[2]])\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:73: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  self.sampling_proportion[2] = torch.tensor([self.sampling_proportion[2]])\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:40: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  censor_ratio = torch.tensor([self.sampling_proportion[0]/self.sampling_proportion[1]]).type(self.dtype)\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:40: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  censor_ratio = torch.tensor([self.sampling_proportion[0]/self.sampling_proportion[1]]).type(self.dtype)\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:41: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  uncensored_ratio = torch.tensor([self.sampling_proportion[2]/self.sampling_proportion[3]]).type(self.dtype)\n",
      "/hps/software/users/gerstung/awj/python/CancerRisk/lib64/python3.6/site-packages/probcox/probcox.py:41: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  uncensored_ratio = torch.tensor([self.sampling_proportion[2]/self.sampling_proportion[3]]).type(self.dtype)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [1:29:47<00:00,  5.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "#=======================================================================================================================\n",
    "pyro.clear_param_store()\n",
    "sampling_props = [pre_p2i.shape[0], np.where(target == labels_short)[0][0], n_subsample, None]\n",
    "m = pcox.PCox(sampling_proportion=sampling_props, predictor=predictor)\n",
    "m.initialize(eta=0.01, num_particles=1, rank=10) \n",
    "\n",
    "loss=[0]\n",
    "for _ in tqdm(range(iter_)):\n",
    "    sindx = np.random.choice(range(pre_p2i.shape[0]), n_subsample, replace=False)\n",
    "    data = longformat(pre=pre, pre_p2i=pre_p2i, sindx=sindx, labels=labels_short, target=target)\n",
    "    loss.append(m.infer(data=data))\n",
    "            \n",
    "g = m.return_guide()\n",
    "theta_est = g.quantiles([0.025, 0.5, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b049bfde-b9eb-4d4d-a0cd-9ae1ef4fbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.concatenate((theta_est['theta'][0].detach().numpy(), theta_est['theta'][1].detach().numpy(), theta_est['theta'][2].detach().numpy()), axis=1).astype(np.float32)\n",
    "out.tofile(f'./out_cox/param/theta_{target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69863744-0ef0-41c7-bb6a-ebc2a1d1ea94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [19:00<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "time = []\n",
    "pred = []\n",
    "\n",
    "for sindx in tqdm(np.array_split(np.arange(pre_p2i.shape[0]), 1000)):\n",
    "    data = longformat(pre=pre, pre_p2i=pre_p2i, sindx=sindx, labels=labels_short, target=target)\n",
    "    with torch.no_grad():\n",
    "        pp = torch.sparse.mm(data[1], theta_est['theta'][1])\n",
    "    time.extend(data[0].numpy().tolist())\n",
    "    pred.extend(pp.numpy().tolist())\n",
    "time = np.asarray(time)\n",
    "pred = np.asarray(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec3b4b90-0a86-4c95-a136-e081037d2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Breslow(times, pred):\n",
    "    times[times[:, -1]==1, 1] = times[times[:, -1]==1, 1] - 0.0000001\n",
    "    event_times = times[times[:, -1] ==1, 1]\n",
    "    event_times = event_times[np.argsort(event_times)]\n",
    "    a0 = [0]\n",
    "    for ii in tqdm(range(event_times.shape[0])):\n",
    "        risk_set = (times[:, 0] < event_times[ii]) * (event_times[ii] <= times[:, 1])\n",
    "        a0.append(1/np.sum(np.exp(pred[risk_set])))\n",
    "    return(event_times, np.asarray(a0[1:]))\n",
    "\n",
    "class A0_fun():\n",
    "    def __init__(self, tt, basehaz):\n",
    "        self.tt = tt\n",
    "        self.basehaz = basehaz\n",
    "        \n",
    "    def __call__(self, ii):\n",
    "        \n",
    "        if np.sum(ii > self.tt) == 0:\n",
    "            return(0)\n",
    "        elif np.sum(ii > self.tt) <= len(self.tt):\n",
    "            return(self.basehaz[np.sum(ii > self.tt)-1][0])\n",
    "        else:\n",
    "            return(self.basehaz[-1][0])\n",
    "\n",
    "def absolute_risk(tt0, tt_range, A0, pred):\n",
    "    A0net = np.sum(A0[tt0:tt0+tt_range]*np.exp(pred))\n",
    "    S0net = 1-np.exp(-np.cumsum(A0net))\n",
    "    return([S0net])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27324ac-39b0-4dc4-97c9-52fb0bbf6467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 2629/35403 [05:42<1:08:47,  7.94it/s]"
     ]
    }
   ],
   "source": [
    "tt, basehaz = Breslow(times=time, pred=pred)    \n",
    "delta_time =[]\n",
    "for jj in np.arange(0, tt.shape[0]-1):\n",
    "    delta_time.append(tt[jj+1] - tt[jj])\n",
    "delta_time.append(0.1)\n",
    "delta_time = np.asarray(delta_time)[:, None]\n",
    "delta_time = np.asarray([np.sum(delta_time[jj==tt], axis=0) for jj in np.unique(tt)])\n",
    "basehaz = np.asarray([np.sum(basehaz[jj==tt], axis=0) for jj in np.unique(tt)])[:, None]\n",
    "tt = np.unique(tt)\n",
    "basehaz = basehaz/delta_time\n",
    "A0 = A0_fun(tt=tt[:-2], basehaz=basehaz[:-2])\n",
    "A0_eval = np.asarray([A0(ii) for ii in range(36500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76b68a44-6137-4815-bb17-5f65c44589ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = theta_est['theta'][1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ea5c63d-2051-4f0d-86c4-c397680c691f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471057/471057 [00:19<00:00, 23641.13it/s]\n"
     ]
    }
   ],
   "source": [
    "age = []\n",
    "sex = []\n",
    "for ii in tqdm(range(pre_p2i.shape[0])):\n",
    "    x = pre[pre_p2i[ii, 0]:pre_p2i[ii, 0]+pre_p2i[ii, 1], 2].astype(int)\n",
    "    a = pre[pre_p2i[ii, 0]:pre_p2i[ii, 0]+pre_p2i[ii, 1], 1].astype(np.float32)\n",
    "    assert np.logical_or(np.any(x==3), np.any(x==2))\n",
    "    sex.extend([np.any(x==3).astype(int)])   \n",
    "    age.extend([a[-1]])\n",
    "sex = np.asarray(sex).astype(int)\n",
    "age = np.asarray(age).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60c5fc85-f923-40d2-a671-338393e1b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471057/471057 [00:21<00:00, 21761.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# hazard\n",
    "N = pre_p2i.shape[0]\n",
    "X = np.zeros((N, labels_short.shape[0]))\n",
    "aa = []\n",
    "for ii in tqdm(range(N)):\n",
    "    with torch.no_grad():\n",
    "        a = pre[pre_p2i[ii, 0]:pre_p2i[ii, 0]+pre_p2i[ii, 1]][:,1][None, :].astype('float32')\n",
    "        x = pre[pre_p2i[ii, 0]:pre_p2i[ii, 0]+pre_p2i[ii, 1]][:,2][None, :].astype('float32')\n",
    "        for jj in x[0, :].astype(int):\n",
    "            X[ii, jj] = 1\n",
    "        aa.extend([np.max(a).tolist()])\n",
    "coxpred = np.matmul(X, theta)\n",
    "aa = np.asarray(aa).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aafdd05-aac9-4eee-aaea-d6b8a38a6d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471057/471057 [00:18<00:00, 25492.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# absolute risk\n",
    "risk = []\n",
    "for ii in tqdm(range(N)):\n",
    "    risk.extend(absolute_risk(tt0=np.minimum(80*365, np.asarray([aa[ii]]))[0], tt_range=900, A0=A0_eval, pred=coxpred[ii]))\n",
    "risk = np.asarray(risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e22a15f-4fa5-4ecf-ba63-4240229ebbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk.astype(np.float32)\n",
    "risk.tofile(f'./out_cox/pred/{target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b17305f-b6d4-48bd-b86a-79896ab10349",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6284ca-95ca-41c0-b170-b69e2d598aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
